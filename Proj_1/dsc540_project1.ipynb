{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSC540 Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DePaul University  \n",
    "Ilyas Ustun, PhD  \n",
    "Chicago, IL  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1X8uH9FQn7ZV"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are the packages I used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your package imports here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules\n",
    "- Do not change the code already present in the notebook.\n",
    "- Write your code under the corresponding questions where you see `# Code here`. You can use more than one cell, if you'd like.\n",
    "- Provide explanation in a separate Markdown formatted cell. \n",
    "- You can change the cell type by:\n",
    "    - Clicking on the outer area of the cell type you want to change,\n",
    "    - Go to the top, and select either Code or Markdown from the dropdown menu.\n",
    "- Be concise in your explanations and conclusions.\n",
    "- Write clear code and provide explanation to functions you create by using `#` comment sign.\n",
    "- For built-in function and methods you use from libraries, provide a very brief explanation of what they do.\n",
    "- Try to answer the questions by yourself. Use documentation from pandas, sklearn and similar libraries to solve the problem.\n",
    "- If you are stuck you can use different resources. Do not find an identical project and copy paste the solutions. \n",
    "- Write your name before beginning to code.\n",
    "\n",
    "\n",
    "Important:  \n",
    "- **Do NOT share the solutions with other people.**\n",
    "- **Do NOT share the solutions on the internet including but not limited to Github and other platforms.**\n",
    "- Sign the Honor Pledge below indicating that you have agreed to these rules listed here, and any other ethical and honor rules as required by the university.\n",
    "\n",
    "\n",
    "\n",
    "- **Deliverables:**\n",
    "    1. The Python Jupyter notebook file named properly with your name. Example: dsc540_project1_john_doe.ipynb\n",
    "    2. The HTML output of this code notebook names the same way. Example: dsc540_project1_john_doe.html\n",
    "        - File -> Download as -> HTML   \n",
    "       \n",
    "\n",
    "Good Luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR NAME HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Honor Pledge:**  \n",
    "I pledge on my honor that I, **Student Name**, have followed the rules listed above, that I have not given or received any unauthorized assistance on this assignment. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will be working with the **Breast Cancer Wisconsin dataset**, which\n",
    "contains 569 examples of malignant and benign tumor cells.  \n",
    "The Breast Cancer Wisconsin dataset can be found in the UCI\n",
    "Machine Learning Repository, and more detailed information about this dataset can\n",
    "be found at https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic).  \n",
    "The first two columns in the dataset store the unique ID numbers of the examples and the corresponding\n",
    "diagnoses (M = malignant, B = benign), respectively.   \n",
    "Columns 3-32 contain 30 real-valued features that have been computed from digitized images of the cell\n",
    "nuclei, which can be used to build a model to predict whether a tumor is benign\n",
    "or malignant.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "HfInD40bJbpC",
    "outputId": "77c4d333-9c77-4013-89ce-e7fca9a97c1c"
   },
   "outputs": [],
   "source": [
    "# Load the dataset from UCI\n",
    "df = pd.read_csv(\n",
    "'https://archive.ics.uci.edu/ml/'\n",
    "'machine-learning-databases'\n",
    "'/breast-cancer-wisconsin/wdbc.data',\n",
    "header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since this dataset does not have headers, we will read the data file that I have created.\n",
    "- Last column is the target column.\n",
    "- The ID column is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('WisconsinBreastCancer.csv')\n",
    "X = df.drop('target', axis=1)\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target vector is `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 [5 points]\n",
    "How many people have cancer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Hint: Should be less than 300!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x number of people have cancer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 [5 points]\n",
    "Check the data and investigate the column types. Is there any categorical data? Any missing values? \n",
    "How many observations? How many variables are there in the feature set (`X`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 [5 points]\n",
    "- Check the statistical summary of numeric features. Do the variables have values close to each other, or is there large differences?\n",
    "- What is the variable that has the largest value?\n",
    "- What is the variable that has the smallest value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 [5 points]\n",
    "These features are all engineered from images. I suspect there is some variables with large correlation. Are there largely correlated variables? Why do you think they are largely correlated? Comment on a few.\n",
    "- Calculate correlation.\n",
    "- Create a correlation heatmap.\n",
    "- Comment on largely correlated variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 [5 points]\n",
    "**Train - Test split** \n",
    "- Use sklearn's `tran_test_split()` function to create the split.\n",
    "- Use `random_state = 55` to create consistent and repeatable train-test splits.\n",
    "\n",
    "- What is the proportion of cancer classes in train and test sets after splitting? Are they equal or very close to each other?\n",
    "- What is the importance of stratified sampling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "51JqRqv2JnOY"
   },
   "outputs": [],
   "source": [
    "# split the datasets into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 55, test_size= 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 [10 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initiate the logistic regression classifier from the sklearn library as shown below.\n",
    "- Fit the model\n",
    "- Make predictions\n",
    "- Calculate accuracy score. What are the **training** and **testing** accuracies of the model?\n",
    "- Create confusion matrix\n",
    "- Either calculate using the confusion matrix, or use the methods in `metrics` to get the following metrics on the testing set:\n",
    "     - Recall (Sensitivity)\n",
    "     - Specificity\n",
    "     - Precision\n",
    "     - False Positive Rate\n",
    "     - F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter = 10000, solver='lbfgs', penalty='l2', C=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_train)\n",
    "metrics.accuracy_score(y_true = y_train, y_pred = pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)\n",
    "metrics.accuracy_score(y_true = y_test, y_pred = pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7 [10 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initiate the k-nearest neighbours classifier from the sklearn library with n_neighbors=1. Keep the remaining parameters with their default values. (No need to specify anything)\n",
    "- Fit the model\n",
    "- Make predictions\n",
    "- Calculate accuracy score. What are the **training** and **testing** accuracies of the model?\n",
    "- Create confusion matrix\n",
    "- Either calculate using the confusion matrix, or using the methods in `metrics` to get the following metrics on the testing set:\n",
    "     - Recall (Sensitivity)\n",
    "     - Specificity\n",
    "     - Precision\n",
    "     - F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8 [10 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initiate the Gaussian Naive Bayes classifier from the sklearn library. Keep all parameters with their default values. (No need to specify anything)\n",
    "- Fit the model\n",
    "- Make predictions\n",
    "- Calculate accuracy score. What are the **training** and **testing** accuracies of the model?\n",
    "- Create confusion matrix\n",
    "- Either calculate using the confusion matrix, or using the methods in `metrics` to get the following metrics on the testing set:\n",
    "     - Recall (Sensitivity)\n",
    "     - Specificity\n",
    "     - Precision\n",
    "     - F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9 [10 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In logistic regression keeping the other parameters constant try these values for C: `C_list = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2, 10, 50, 100, 200, 500, 1000, 2000, 5000, 10000]`.  \n",
    "C is the inverse of the regularization parameter $\\lambda$. As C increases, the penalty decreases.\n",
    "- Create a loop and fit the models using each C value. \n",
    "- Make predictions\n",
    "- Calculate accuracy scores for **training** and **testing** datasets. Create a list of accuracy results for train and test accuracies. Show these lists.\n",
    "- Plot the validation curve based on each C value and the corresponding the train and test accuracies. \n",
    "> Create this curve yourself. Do not use sklearn built-in function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_list = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2, 10, 50, 100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "for C in C_list:\n",
    "    clf = LogisticRegression(max_iter = 10000, solver='lbfgs', penalty='l2', C=C)\n",
    "    # Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10 [10 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In K Nearest Neighbors keeping the other parameters constant try these values for K (n_neighbors): `K_list = [1,3,5,7,9,15,19,25,29,35,39,45,49,99]`.  \n",
    "- Create a loop and fit the models using each K value. \n",
    "- Make predictions\n",
    "- Calculate accuracy scores for **training** and **testing** datasets. Create a list of accuracy results for train and test accuracies. Show these lists.\n",
    "- Create the validation curve based on each K value and the corresponding the train and test accuracies. \n",
    "> Create this curve yourself. Do not use sklearn built-in function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_list = [1,3,5,7,9,15,19,25,29,35,39,45,49,99]\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "for K in K_list:\n",
    "    clf = KNeighborsClassifier(n_neighbors=K)\n",
    "    # Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11 [10 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The validation curve for logistic regression seems a bit weird. That might have to do with the fact that the data is not normalized.\n",
    "- Apply standardization to the data and re-do Quesion 9 and plot the validation curve for logistic regression models with same parameter range for C. \n",
    "- Plot the validation curve. What do you see? \n",
    "- Which value would you choose for C in logistic regression? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = preprocessing.StandardScaler()\n",
    "X_train_ss = ss.fit_transform(X_train)\n",
    "X_test_ss = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12 [5 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ss[0:426,:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After choosing your best C value, let's check the learning curve.\n",
    "- Create a logistic regression model of your chosen C value, and the other parameters the same as before.\n",
    "- Starting from 1 data point in the training set, increase your training set size by 1 point in each iteration, fit the model, get the accuracy scores for both the current training and test sets.\n",
    "- Increase the training set size consecutively. Do not randomly select data points. (`X_train_ss[0:N,:] where N = {1,2,3,...,len(X_train_ss)}`)\n",
    "- Plot the learning curve. What do you see? Comment on your finding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13 [5 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Before applying KNN, it is important to scale the features. \n",
    "- Use the standardized train and test sets re-do Quesion 10 and plot the validation curve for KNN models with same parameter range for K. \n",
    "- Plot the validation curve. What do you see? \n",
    "- Which value would you choose for K in nearest neighbor model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14 [10 points]\n",
    "- Using only the classifier models of logistic regression, Gaussian Naive Bayes, or KNN models:\n",
    "    - Think of other ways of improving the accuracy and list at least two possibilities.\n",
    "    - Implement one of the methods you proposed. \n",
    "    - Is the model accuracy increasing? Why do you think this might have helped?\n",
    "    - If it not increasing, try the other method you proposed. Why do you think this might have helped?\n",
    "    - If none of them did not improve, comment on why this might have been the case.\n",
    "    - If you have time try a few more solutions and see which one works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Multiclass Classification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
